{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch_geometric.nn import GCNConv, GraphConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Helper function for visualization.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cell_txt(file_path):\n",
    "    cells = []  # 用于存储解析后的数据\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for i in range(0, len(lines), 3):\n",
    "        # 每三行表示一个cell的数据\n",
    "        center_line = lines[i].strip()\n",
    "        cell_neighbors_line = lines[i + 1].strip()\n",
    "        node_neighbors_line = lines[i + 2].strip()\n",
    "\n",
    "        # 解析中心位置和半径\n",
    "        center_data = list(map(float, center_line.split()))\n",
    "        cell_center = {\n",
    "            \"x\": center_data[0],\n",
    "            \"y\": center_data[1],\n",
    "            \"z\": center_data[2],\n",
    "            \"radius\": center_data[3]\n",
    "        }\n",
    "\n",
    "        # 解析cell的连接关系\n",
    "        cell_neighbors = list(map(int, cell_neighbors_line.split()))\n",
    "\n",
    "        # 解析node的连接关系\n",
    "        node_neighbors = list(map(int, node_neighbors_line.split()))\n",
    "\n",
    "        # 组合到一个字典\n",
    "        cell = {\n",
    "            \"cell_center\": cell_center,\n",
    "            \"cell_neighbors\": cell_neighbors,\n",
    "            \"node_neighbors\": node_neighbors\n",
    "        }\n",
    "\n",
    "        # 添加到结果列表\n",
    "        cells.append(cell)\n",
    "\n",
    "    return cells\n",
    "\n",
    "def sort_nodes_and_edges(node_features_np: np.ndarray, edges_np: np.ndarray):\n",
    "    \"\"\"\n",
    "    对节点按 (r, x, phi) 排序，并更新边的索引。\n",
    "\n",
    "    Args:\n",
    "        node_features (numpy.ndarray): 节点特征，形状为 [num_nodes, feature_dim]。\n",
    "        edges (numpy.ndarray): 边列表，形状为 [2, num_edges]。\n",
    "\n",
    "    Returns:\n",
    "        sorted_node_features: 排序后的节点特征 (torch.Tensor)。\n",
    "        sorted_edges: 排序后的边索引 (torch.Tensor)。\n",
    "    \"\"\"\n",
    "    # 提取 x, y, z 坐标\n",
    "    x = node_features_np[:, 0]\n",
    "    y = node_features_np[:, 1]\n",
    "    z = node_features_np[:, 2]\n",
    "\n",
    "    # 计算球坐标\n",
    "    r = np.sqrt(x**2 + y**2 + z**2)\n",
    "    phi = np.arctan2(z, y) % (2 * np.pi)\n",
    "\n",
    "    # 构造球坐标用于排序\n",
    "    spherical_coords = np.stack((r, x, phi), axis=1)\n",
    "\n",
    "    # 按球坐标排序 (r, x, phi)\n",
    "    sorted_order = np.lexsort((spherical_coords[:, 2], spherical_coords[:, 1], spherical_coords[:, 0]))\n",
    "    sorted_node_features_np = node_features_np[sorted_order]\n",
    "\n",
    "    # 创建从原始索引到排序后索引的映射\n",
    "    index_mapping = {original_idx: sorted_idx for sorted_idx, original_idx in enumerate(sorted_order)}\n",
    "\n",
    "    # 更新边索引\n",
    "    sorted_edges = []\n",
    "    for edge in edges_np:  # 遍历每条边\n",
    "        node1, node2 = edge\n",
    "        sorted_node1 = index_mapping[node1]\n",
    "        sorted_node2 = index_mapping[node2]\n",
    "        sorted_edges.append([sorted_node1, sorted_node2])\n",
    "\n",
    "    return sorted_node_features_np, sorted_edges\n",
    "\n",
    "def get_gnn_dataset(cells, device):\n",
    "    \"\"\"\n",
    "    根据解析后的cells数据构建GNN数据集\n",
    "    Args:\n",
    "        cells (list): 包含每个cell的中心和连接关系的字典列表\n",
    "    Returns:\n",
    "        torch_geometric.data.Data: 包含节点特征和边信息的图数据\n",
    "    \"\"\"\n",
    "    # 节点特征: 使用cell_center (x, y, z, radius)\n",
    "    node_features = []\n",
    "    edges = []\n",
    "\n",
    "    for node_id, cell in enumerate(cells):\n",
    "        # 添加节点特征\n",
    "        center = cell[\"cell_center\"]\n",
    "        node_features.append([center[\"x\"], center[\"y\"], center[\"z\"], center[\"radius\"]])\n",
    "\n",
    "        # 添加边: 从当前节点到其邻居\n",
    "        for neighbor_id in cell[\"cell_neighbors\"]:\n",
    "            # 添加双向边\n",
    "            edges.append((node_id, neighbor_id))\n",
    "            edges.append((neighbor_id, node_id))\n",
    "    \n",
    "    # 转换为numpy数组\n",
    "    node_features_np = np.array(node_features)\n",
    "    edges_np = np.array(edges)\n",
    "    edges_np = np.unique(edges_np, axis=0)  # 去重\n",
    "\n",
    "    # 对节点和边进行排序\n",
    "    sorted_node_features_np, sorted_edges_np = sort_nodes_and_edges(node_features_np, edges_np)\n",
    "\n",
    "    # 转换为torch.Tensor\n",
    "    node_features_tensor = torch.tensor(sorted_node_features_np, dtype=torch.float).to(device)\n",
    "    edges_tensor = torch.tensor(sorted_edges_np, dtype=torch.long).t().contiguous().to(device)\n",
    "\n",
    "    # 创建图数据\n",
    "    data = Data(x=node_features_tensor[:,3:], edge_index=edges_tensor)\n",
    "    data.pos = node_features_tensor[:,0:3]\n",
    "\n",
    "    return data\n",
    "\n",
    "def load_target_data(filename, device):\n",
    "    \"\"\"\n",
    "    Loads ray data from parameter file.\n",
    "    \"\"\"\n",
    "    datafile = filename\n",
    "\n",
    "    parameters = torch.load(filename, map_location=device) \n",
    "    w_logits = parameters['w_logits']\n",
    "    theta_phi = parameters['theta_phi']\n",
    "    log_kappa = parameters['log_kappa']\n",
    "    theta = theta_phi[:log_kappa.size(0)]\n",
    "    phi = theta_phi[log_kappa.size(0):]\n",
    "    indices = np.lexsort((-phi.cpu().numpy(), -theta.cpu().numpy(), -log_kappa.cpu().numpy(), -w_logits.cpu().numpy()))\n",
    "    sorted_indices = torch.tensor(indices)\n",
    "    target_data = torch.stack([w_logits,log_kappa,theta,phi], dim=1)\n",
    "    target_data = target_data[sorted_indices,:]\n",
    "    target_data = torch.flatten(target_data)\n",
    "    return target_data.to(device)\n",
    "    \n",
    "# 多重 von Mises-Fisher 分布函数\n",
    "def multi_vmf(weights, axes, kappas, w):\n",
    "    # Ensure kappas are non-negative for stability\n",
    "    kappas = torch.clamp(kappas, min=1e-10, max=1e5)\n",
    "\n",
    "    # Define thresholds for approximations\n",
    "    large_kappa_threshold = 1e5  # Threshold for considering kappa as \"large\"\n",
    "    small_kappa_threshold = 1e-3  # Threshold for considering kappa as \"small\"\n",
    "\n",
    "    # Approximate normalization constant for large and small kappa values\n",
    "\n",
    "\n",
    "    norm_const = torch.where(\n",
    "        kappas > large_kappa_threshold,\n",
    "        kappas / (2 * math.pi),  # Approximation for large kappa\n",
    "        kappas / (2 * math.pi * (1-torch.exp(-2*kappas)))\n",
    "    )\n",
    "    # norm_const = kappas / (4 * math.pi * (1-torch.exp(-2*kappas)))\n",
    "\n",
    "    # Compute dot products between input w and the axes of the spheres (unit vectors)\n",
    "    dot_products = torch.matmul(w, axes.transpose(0, 1))-1  # Shape: (data_sizes, num_spheres)\n",
    "\n",
    "    # Compute the weighted von Mises-Fisher pdf values\n",
    "    weighted_exps = weights * norm_const * torch.exp(kappas * dot_products)  # Shape: (data_sizes, num_spheres)\n",
    "    q = torch.sum(weighted_exps, dim=-1)  # Shape: (data_sizes,)\n",
    "    q = torch.clamp(q, min=1e-10, max=1e10)  # Further clamping to avoid extreme values\n",
    "    return q\n",
    "\n",
    "def plot_outputs_3d(references, predictions, sizes, save_path=None):\n",
    "    # 定义 z 和 phi 的范围\n",
    "    z_min, z_max = -1, 1\n",
    "    phi_min, phi_max = -np.pi, np.pi\n",
    "\n",
    "    # 创建用于 3D 绘图的网格\n",
    "    z_in = np.linspace(z_min, z_max, sizes[0])\n",
    "    phi_in = np.linspace(phi_min, phi_max, sizes[1])\n",
    "\n",
    "    Z, Phi = np.meshgrid(z_in, phi_in, indexing='ij')\n",
    "\n",
    "    target_img = references\n",
    "    predict_img = predictions\n",
    "\n",
    "    # 确保输入数据的形状与网格匹配\n",
    "    if predict_img.shape != Z.shape:\n",
    "        predict_img = predict_img.reshape(Z.shape)\n",
    "    if target_img is not None and target_img.shape != Z.shape:\n",
    "        target_img = target_img.reshape(Z.shape)\n",
    "\n",
    "    # 设置用于 3D 可视化的子图\n",
    "    if target_img is not None and np.sum(target_img) > 0:\n",
    "        fig = plt.figure(figsize=(14, 6))\n",
    "        ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "        ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax1 = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "\n",
    "    # 绘制预测数据的 3D 曲面\n",
    "    ax1.plot_surface(Z, Phi, predict_img, rstride=1, cstride=1, cmap='rainbow')\n",
    "    ax1.set_title('Prediction')\n",
    "    ax1.set_xlabel('Z')\n",
    "    ax1.set_ylabel('Phi')\n",
    "    ax1.set_zlabel('Value')\n",
    "\n",
    "    # 如果有参考数据，绘制其 3D 曲面\n",
    "    if target_img is not None and np.sum(target_img) > 0:\n",
    "        ax2.plot_surface(Z, Phi, target_img, rstride=1, cstride=1, cmap='rainbow')\n",
    "        ax2.set_title('Reference')\n",
    "        ax2.set_xlabel('Z')\n",
    "        ax2.set_ylabel('Phi')\n",
    "        ax2.set_zlabel('Value')\n",
    "\n",
    "    # 显示图形\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "def get_gridX(sizes):\n",
    "    i_idx = torch.arange(sizes[0], dtype=torch.float, device=device) / sizes[0]\n",
    "    j_idx = torch.arange(sizes[1], dtype=torch.float, device=device) / sizes[1]\n",
    "    i_grid, j_grid = torch.meshgrid(i_idx, j_idx)\n",
    "    pos_x = i_grid * 2 - 1\n",
    "    pos_phi = (j_grid * 2 - 1) * np.pi\n",
    "    pos_r = torch.sqrt(1 - pos_x**2)\n",
    "    pos_y = pos_r * torch.cos(pos_phi)\n",
    "    pos_z = pos_r * torch.sin(pos_phi)\n",
    "    X = torch.stack((pos_x, pos_y, pos_z), dim=-1).reshape(-1, 3).to(device)\n",
    "    return X\n",
    "\n",
    "\n",
    "# 加载 ray 数据的函数\n",
    "def load_rawdata(filename, sizes, device, verbose=False):\n",
    "    X = get_gridX(sizes)\n",
    "\n",
    "    rawdata = np.fromfile(filename, dtype=np.float32)\n",
    "    rawdata = rawdata.reshape(-1, 4)\n",
    "    # print(rawdata.shape)\n",
    "    x = rawdata[:,0]\n",
    "    # print(np.max(data[:,1]))\n",
    "    phi = rawdata[:,1]-np.pi\n",
    "    r = np.sqrt(1 - x**2)\n",
    "    y = r * np.cos(phi)\n",
    "    z = r * np.sin(phi)\n",
    "\n",
    "\n",
    "    # 创建网格分布\n",
    "    x_edges = np.linspace(-1, 1, sizes[0]+1)  \n",
    "    phi_edges = np.linspace(-np.pi, np.pi, sizes[1]+1)\n",
    "\n",
    "    # 统计 (X, φ) 分布\n",
    "    H, _, _ = np.histogram2d(x, phi, bins=[x_edges, phi_edges])\n",
    "    ray_data = torch.tensor(H, dtype=torch.float32, device=device).reshape(-1, 1)\n",
    "    if ray_data.shape[0] != sizes[0] * sizes[1]:\n",
    "        print(\"Error: ray data shape mismatch!\")\n",
    "        exit(1)\n",
    "    area = 4 * math.pi / (ray_data.shape[0])\n",
    "    ray_data = ray_data / torch.sum(ray_data) / area\n",
    "    \n",
    "\n",
    "    raw_X = np.column_stack((x, y, z))\n",
    "    raw_num = min(4096, raw_X.shape[0])\n",
    "    raw_X = raw_X[:raw_num, :]\n",
    "\n",
    "    # 将数据转换为张量\n",
    "    raw_data = torch.tensor(raw_X, dtype=torch.float32, device=device)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"X Mesh shape:\", X.shape)\n",
    "        print(\"ray data shape:\", ray_data.shape)\n",
    "        print(\"raw data shape:\", raw_data.shape)\n",
    "    return raw_data, ray_data, X\n",
    "\n",
    "\n",
    "def generate_filenames(base_path, target_file, num_files):\n",
    "    \"\"\"生成文件路径列表\"\"\"\n",
    "    return [os.path.join(base_path, f\"{i}\", target_file) for i in range(0, num_files)]\n",
    "\n",
    "def smooth_curve(values, smoothing_factor=0.9):\n",
    "    smoothed_values = []\n",
    "    last = values[0]\n",
    "    for value in values:\n",
    "        smoothed_value = last * smoothing_factor + (1 - smoothing_factor) * value\n",
    "        smoothed_values.append(smoothed_value)\n",
    "        last = smoothed_value\n",
    "    return smoothed_values\n",
    "\n",
    "def plot_losses(train_losses, val_losses = None):\n",
    "    train_losses_smoothed = smooth_curve(train_losses)\n",
    "    if val_losses is not None:\n",
    "        val_losses_smoothed = smooth_curve(val_losses)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses_smoothed, label=\"Training Loss (Smoothed)\", color=\"blue\")\n",
    "    if val_losses is not None:\n",
    "        plt.plot(val_losses_smoothed, label=\"Validation Loss (Smoothed)\", color=\"red\")\n",
    "    plt.yscale(\"log\")  # Log scale for the y-axis\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss (Log Scale)\")\n",
    "    plt.title(\"Loss (Log Scale with Smoothing)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def extract_param(vmf_param):\n",
    "    vmf_param = vmf_param.reshape(-1,4)  \n",
    "    weights = F.softmax(vmf_param[:,0],dim=-1)\n",
    "    kappas = torch.exp(vmf_param[:,1])\n",
    "    theta = torch.sigmoid(vmf_param[:,2])* math.pi \n",
    "    phi = torch.sigmoid(vmf_param[:,3])* math.pi * 2\n",
    "    cos_theta = torch.cos(theta)\n",
    "    sin_theta = torch.sin(theta)\n",
    "    cos_phi = torch.cos(phi)\n",
    "    sin_phi = torch.sin(phi)\n",
    "    mus = torch.stack((sin_theta * cos_phi, sin_theta * sin_phi, cos_theta), dim=1)\n",
    "    return weights, mus, kappas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        \"\"\"\n",
    "        Initializes the PositionalEncoder module.\n",
    "\n",
    "        Parameters:\n",
    "        - L (int): Number of frequency components in the encoding.\n",
    "        \"\"\"\n",
    "        super(PositionalEncoder, self).__init__()\n",
    "        self.L = L\n",
    "\n",
    "        # Precompute the frequency terms (2^k * pi)\n",
    "        frequencies = torch.tensor([1 << i for i in range(L)], dtype=torch.float32) * math.pi\n",
    "        self.register_buffer('frequencies', frequencies)  # Shape: (L,)\n",
    "\n",
    "    def forward(self, p):\n",
    "        \"\"\"\n",
    "        Computes the positional encoding gamma(p) for a given input p in the range [-1, 1].\n",
    "\n",
    "        Parameters:\n",
    "        - p (torch.Tensor): Input tensor of shape (batch_size, dim) with values in the range [-1, 1].\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: Positional encoding of shape (batch_size, dim * L).\n",
    "        \"\"\"\n",
    "        # Ensure p is on the same device as frequencies\n",
    "        # (Not needed since frequencies will be moved with the model)\n",
    "\n",
    "        # Ensure p has the correct shape to broadcast with frequencies\n",
    "        p = p.unsqueeze(-1)  # Shape: (batch_size, dim, 1)\n",
    "        \n",
    "        # Apply sin transformation only\n",
    "        sin_encodings = torch.sin(p * self.frequencies)  # Shape: (batch_size, dim, L) \n",
    "\n",
    "        return sin_encodings.view(p.size(0), -1)  # Shape: (batch_size, dim * L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# GCN Module with Residual Connections\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        # GCN Layers\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.skip1 = nn.Linear(num_features, hidden_channels) if num_features != hidden_channels else nn.Identity()\n",
    "        self.skip2 = nn.Identity()\n",
    "        self.skip3 = nn.Identity()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # First Layer with Skip Connection\n",
    "        residual = self.skip1(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x + residual)\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        \n",
    "        # Second Layer with Skip Connection\n",
    "        residual = self.skip2(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x + residual)\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        \n",
    "        # Third Layer with Skip Connection\n",
    "        residual = self.skip3(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x + residual)\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "        self.conv3.reset_parameters()\n",
    "        if isinstance(self.skip1, nn.Linear):\n",
    "            self.skip1.reset_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    " \n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GELU, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + F.tanh(0.79788456080286535 * (x + 0.044715 * x * x * x)))\n",
    "    \n",
    "# Residual Attention Block\n",
    "class ResidualAttentionBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, n_head: int):\n",
    "        super(ResidualAttentionBlock, self).__init__()\n",
    "        self.attn = nn.MultiheadAttention(d_model, n_head)\n",
    "        self.ln_1 = nn.LayerNorm(d_model)\n",
    "        self.mlp = nn.Sequential(OrderedDict([\n",
    "            (\"c_fc\", nn.Linear(d_model, d_model * 4)),\n",
    "            (\"gelu\", GELU()),\n",
    "            (\"c_proj\", nn.Linear(d_model * 4, d_model))\n",
    "        ]))\n",
    "        self.ln_2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def attention(self, x: torch.Tensor, key_padding_mask: torch.Tensor = None):\n",
    "        return self.attn(x, x, x, key_padding_mask=key_padding_mask)[0]\n",
    "\n",
    "    def forward(self, x: torch.Tensor, key_padding_mask: torch.Tensor = None):\n",
    "        x = x + self.attention(self.ln_1(x), key_padding_mask=key_padding_mask)\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "# Transformer Module\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, width: int, layers: int, heads: int):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.width = width\n",
    "        self.layers = layers\n",
    "        self.resblocks = nn.ModuleList([\n",
    "            ResidualAttentionBlock(width, heads) for _ in range(layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor, key_padding_mask: torch.Tensor = None):\n",
    "        for block in self.resblocks:\n",
    "            x = block(x, key_padding_mask=key_padding_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCNTransformer class, mimicking Vision Transformer structure\n",
    "class GCNTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int,\n",
    "        transformer_width: int,\n",
    "        transformer_layers: int,\n",
    "        transformer_heads: int,\n",
    "        hidden_dim: int,\n",
    "        output_dim: int,\n",
    "        embedding_dim: int,  # Number of frequency components for PositionalEncoder\n",
    "        pos_dim: int,  # Dimension of positional features\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super(GCNTransformer, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # Positional Encoder\n",
    "        self.positional_encoder = PositionalEncoder(L=embedding_dim)\n",
    "\n",
    "        # GCN module\n",
    "        self.gcn = GCN(num_features + embedding_dim*pos_dim, embedding_dim)\n",
    "\n",
    "        # [CLS] token as a learnable embedding\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, transformer_width))\n",
    "\n",
    "        # Mapping GCN output to Transformer input dimension\n",
    "        self.gcn_to_transformer = nn.Linear(embedding_dim*(pos_dim+1), transformer_width)\n",
    "\n",
    "        # Layer normalization before Transformer\n",
    "        self.ln_pre = nn.LayerNorm(transformer_width)\n",
    "\n",
    "        # If positional encoding increases the dimension, adjust the transformer width accordingly\n",
    "        self.transformer = Transformer(width=transformer_width, layers=transformer_layers, heads=transformer_heads)\n",
    "\n",
    "        # Layer normalization after Transformer\n",
    "        self.ln_post = nn.LayerNorm(transformer_width)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(transformer_width, hidden_dim),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "        # Initialize GCN to Transformer mapping\n",
    "        nn.init.trunc_normal_(self.gcn_to_transformer.weight, std=0.02)\n",
    "        if self.gcn_to_transformer.bias is not None:\n",
    "            nn.init.zeros_(self.gcn_to_transformer.bias)\n",
    "        # Positional Encoder weightare fixed (sinusoidal), no initialization needed\n",
    "\n",
    "    def forward(self, x, edge_index, p, batch):\n",
    "        \"\"\"\n",
    "        x: [total_num_nodes, num_features]\n",
    "        edge_index: [2, num_edges]\n",
    "        p: [total_num_nodes, pos_dim], positional features for each node in the range [-1, 1]\n",
    "        batch: [total_num_nodes], indicating the graph index each node belongs to\n",
    "        \"\"\"\n",
    "\n",
    "        pos_enc = self.positional_encoder(p)  # [total_num_nodes, embedding_dim * pos_dim]\n",
    "\n",
    "        x = torch.cat([x, pos_enc], dim=-1)  # [total_num_nodes, num_features + embedding_dim * pos_dim]\n",
    "        # Extract node features using GCN\n",
    "        x = self.gcn(x, edge_index)  # [total_num_nodes, embedding_dim]\n",
    "\n",
    "        x = torch.cat([x, pos_enc], dim=-1) # [total_num_nodes, embedding_dim*(pos_dim+1)]\n",
    "\n",
    "        # Map to Transformer input dimension\n",
    "        x = self.gcn_to_transformer(x)  # [total_num_nodes, transformer_width]\n",
    "\n",
    "        x_dense, mask = to_dense_batch(x, batch)  # x_dense: [batch_size, max_num_nodes, transformer_width]; mask: [batch_size, max_num_nodes]\n",
    "\n",
    "        batch_size, max_num_nodes, _ = x_dense.size()\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # [batch_size, 1, transformer_width]\n",
    "        x_dense = torch.cat([cls_tokens, x_dense], dim=1)  # [batch_size, 1 + max_num_nodes, transformer_width]\n",
    "\n",
    "        # Add True for [CLS] tokens\n",
    "        cls_mask = torch.ones(batch_size, 1, dtype=torch.bool, device=x.device)\n",
    "        attention_mask = torch.cat([cls_mask, mask], dim=1)  # [batch_size, 1 + max_num_nodes]\n",
    "\n",
    "        # Permute to match Transformer input shape (sequence_length, batch_size, embedding_dim)\n",
    "        x_dense = x_dense.permute(1, 0, 2)  # [1 + max_num_nodes, batch_size, transformer_width]\n",
    "\n",
    "        # Forward pass through Transformer\n",
    "        x_transformed = self.transformer(x_dense, key_padding_mask=~attention_mask)  # [1 + max_num_nodes, batch_size, transformer_width]\n",
    "\n",
    "        # Permute back to (batch_size, sequence_length, embedding_dim)\n",
    "        x_transformed = x_transformed.permute(1, 0, 2)  # [batch_size, 1 + max_num_nodes, transformer_width]\n",
    "\n",
    "        # Extract the [CLS] token's features\n",
    "        cls_features = self.ln_post(x_transformed[:, 0, :])  # [batch_size, transformer_width]\n",
    "\n",
    "        # Pass through the decoder\n",
    "        out = self.decoder(cls_features)  # [batch_size, output_dim]\n",
    "\n",
    "        return out  # [batch_size, output_dim]\n",
    "\n",
    "    def vmf_param(self, x, edge_index, p, batch):\n",
    "        \"\"\"\n",
    "        计算模型输出的von Mises-Fisher (vMF)分布参数。\n",
    "        \n",
    "        参数：\n",
    "        - x (torch.Tensor): 节点特征矩阵，形状为 [total_num_nodes, num_features]\n",
    "        - edge_index (torch.Tensor): 边索引，形状为 [2, num_edges]\n",
    "        - p (torch.Tensor): 位置特征，形状为 [total_num_nodes, pos_dim]，范围为 [-1, 1]\n",
    "        - batch (torch.Tensor): 批量向量，指示每个节点所属的图，形状为 [total_num_nodes]\n",
    "        \n",
    "        返回：\n",
    "        - weights (torch.Tensor): [batch_size, num_vmf]\n",
    "        - mus (torch.Tensor): [batch_size, num_vmf, 3]\n",
    "        - kappas (torch.Tensor): [batch_size, num_vmf]\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # 前向传播，获取模型输出\n",
    "            out = self(x, edge_index, p, batch)  # [batch_size, output_dim]\n",
    "            \n",
    "            # 确定批量大小和vMF组件的数量\n",
    "            batch_size = out.size(0)  # [batch_size]\n",
    "            output_dim = out.size(1)  # output_dim = num_vmf * 4\n",
    "            assert output_dim % 4 == 0, \"Output dimension must be divisible by 4 for vMF parameters\"\n",
    "            num_vmf = output_dim // 4  # 每个图的vMF组件数量\n",
    "            \n",
    "            # 重塑输出为 [batch_size, num_vmf, 4]\n",
    "            out = out.view(batch_size, num_vmf, 4)  # [batch_size, num_vmf, 4]\n",
    "            \n",
    "            # 计算vMF参数\n",
    "            weights = F.softmax(out[:, :, 0], dim=-1)  # [batch_size, num_vmf]\n",
    "            kappas = torch.exp(out[:, :, 1])           # [batch_size, num_vmf]\n",
    "            theta = torch.sigmoid(out[:, :, 2]) * math.pi  # [batch_size, num_vmf]\n",
    "            phi = torch.sigmoid(out[:, :, 3]) * math.pi * 2  # [batch_size, num_vmf]\n",
    "            \n",
    "            # 将球面坐标（theta, phi）转换为笛卡尔坐标（mu向量）\n",
    "            cos_theta = torch.cos(theta)  # [batch_size, num_vmf]\n",
    "            sin_theta = torch.sin(theta)  # [batch_size, num_vmf]\n",
    "            cos_phi = torch.cos(phi)      # [batch_size, num_vmf]\n",
    "            sin_phi = torch.sin(phi)      # [batch_size, num_vmf]\n",
    "            \n",
    "            # 组合mu向量： [batch_size, num_vmf, 3]\n",
    "            mus = torch.stack(\n",
    "                (sin_theta * cos_phi, sin_theta * sin_phi, cos_theta),\n",
    "                dim=-1\n",
    "            )  # [batch_size, num_vmf, 3]\n",
    "            \n",
    "            return weights, mus, kappas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(output, target):\n",
    "    \"\"\"\n",
    "    Computes the mean squared error loss.\n",
    "\n",
    "    Parameters:\n",
    "    - output (torch.Tensor): Output tensor of the model.\n",
    "    - target (torch.Tensor): Target tensor.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Loss value.\n",
    "    \"\"\"\n",
    "    return F.mse_loss(output, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\runze\\AppData\\Local\\Temp\\ipykernel_25308\\2579602662.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  parameters = torch.load(filename, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# 基础路径和 foam 名称列表\n",
    "base_path = \"D:\\\\Github\\\\datasets\\\\raw_data\"\n",
    "foam_names = [\"foam0\", \"foam1\", \"foam2\", \"foam3\", \"foam4\", \"foam5\"]\n",
    "file_num = 14\n",
    "\n",
    "# 文件名\n",
    "cell_path = \"cells.txt\"\n",
    "param_path = \"vmf_parameters.pth\"\n",
    "raw_path = \"rawdataNonSpe.bin\"\n",
    "\n",
    "# 网格大小\n",
    "sizes = [64, 64]\n",
    "X = get_gridX(sizes)\n",
    "\n",
    "# 初始化数据集列表\n",
    "datasets = []\n",
    "ray_datasets = []\n",
    "\n",
    "# 遍历所有 foam 文件夹\n",
    "for foam_name in foam_names:\n",
    "    folder_path = os.path.join(base_path, foam_name)\n",
    "    \n",
    "    # Generate file paths\n",
    "    graphs_path = generate_filenames(folder_path, cell_path, file_num)\n",
    "    target_path = generate_filenames(folder_path, param_path, file_num)\n",
    "    rays_path = generate_filenames(folder_path, raw_path, file_num)\n",
    "    \n",
    "    # Load data for each file\n",
    "    for i in range(file_num):\n",
    "        # Load graph data\n",
    "        parsed_cells = parse_cell_txt(graphs_path[i])\n",
    "        graph_data = get_gnn_dataset(parsed_cells, device)\n",
    "        \n",
    "        # Load target data\n",
    "        target_data = load_target_data(target_path[i], device)\n",
    "        graph_data.y = target_data.reshape(-1)  # 确保目标数据形状为 [output_dim]\n",
    "        graph_data.batch = torch.zeros(graph_data.num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "        # Load raw data\n",
    "        _, ray_data, _ = load_rawdata(rays_path[i], sizes, device)\n",
    "        ray_datasets.append(ray_data)\n",
    "        \n",
    "        datasets.append(graph_data)\n",
    "\n",
    "# Create a DataLoader with the datasets\n",
    "batch_size = 16  # According to the available GPU memory\n",
    "data_loader = DataLoader(datasets, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "Data(x=[562, 1], edge_index=[2, 6350], pos=[562, 3], y=[256], batch=[562])\n",
      "\n",
      "Sample 1:\n",
      "Data(x=[517, 1], edge_index=[2, 5878], pos=[517, 3], y=[256], batch=[517])\n",
      "\n",
      "Sample 2:\n",
      "Data(x=[562, 1], edge_index=[2, 6350], pos=[562, 3], y=[256], batch=[562])\n",
      "\n",
      "Sample 3:\n",
      "Data(x=[577, 1], edge_index=[2, 6570], pos=[577, 3], y=[256], batch=[577])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(datasets))\n",
    "val_size = len(datasets) - train_size\n",
    "train_dataset, val_dataset = random_split(datasets, [train_size, val_size])\n",
    "\n",
    "num_samples = 4\n",
    "random_samples = random.sample(list(train_dataset), min(num_samples, len(train_dataset)))\n",
    "for i, data in enumerate(random_samples):\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "hyperparameters = {\n",
    "    'num_features': datasets[0].x.size(1),\n",
    "    'transformer_width': 256,\n",
    "    'transformer_layers': 4,\n",
    "    'transformer_heads': 8,\n",
    "    'embedding_dim': 64,        # PositionalEncoder 的频率分量数\n",
    "    'pos_dim': datasets[0].pos.size(1),\n",
    "    'dropout': 0.1,\n",
    "    'hidden_dim': 128,\n",
    "    'output_dim': 256,\n",
    "    'num_epochs': 2000,\n",
    "    'lr': 5e-4,\n",
    "    'gamma': 0.9995,\n",
    "    'step_size': 10,\n",
    "    'batch_size': 16\n",
    "}\n",
    "\n",
    "# 初始化模型\n",
    "gcn_transformer = GCNTransformer(\n",
    "    num_features=hyperparameters['num_features'],\n",
    "    transformer_width=hyperparameters['transformer_width'],\n",
    "    transformer_layers=hyperparameters['transformer_layers'],\n",
    "    transformer_heads=hyperparameters['transformer_heads'],\n",
    "    hidden_dim=hyperparameters['hidden_dim'],\n",
    "    output_dim=hyperparameters['output_dim'],\n",
    "    embedding_dim=hyperparameters['embedding_dim'],\n",
    "    pos_dim=hyperparameters['pos_dim'],\n",
    "    dropout=hyperparameters['dropout'],\n",
    ").to(device)\n",
    "\n",
    "# 初始化优化器和调度器\n",
    "optimizer = Adam(gcn_transformer.parameters(), lr=hyperparameters['lr'])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    gamma=hyperparameters['gamma'],\n",
    "    step_size=hyperparameters['step_size']\n",
    ")\n",
    "\n",
    "# 初始化数据加载器\n",
    "data_loader = DataLoader(\n",
    "    datasets,\n",
    "    batch_size=hyperparameters['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 初始化训练相关的其他变量\n",
    "loss_history = []\n",
    "current_epoch = 0  # 如果从头开始训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,num_epochs, data_loader, optimizer,scheduler=None):\n",
    "    loss_history = []\n",
    "    with tqdm(total=num_epochs, desc=\"Training Progress\") as pbar:\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0\n",
    "            count = 0\n",
    "            # Iterate over pre-loaded data with tqdm for progress visualization\n",
    "            for batch_data in data_loader:\n",
    "                batch_data = batch_data.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                predictions = gcn_transformer(\n",
    "                    batch_data.x,\n",
    "                    batch_data.edge_index,\n",
    "                    batch_data.pos,\n",
    "                    batch_data.batch\n",
    "                ).reshape(-1)\n",
    "                # Compute the loss\n",
    "                loss = criterion(predictions, batch_data.y)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                count += 1\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            average_loss = total_loss/count\n",
    "            loss_history.append(average_loss)\n",
    "            pbar.set_postfix({\n",
    "                'Loss': f\"{average_loss:.6f}\"\n",
    "            })\n",
    "            pbar.update(1)\n",
    "        tqdm.write(\"Training complete!\")\n",
    "    return loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = train_model(gcn_transformer,hyperparameters['num_epochs'], data_loader, optimizer,scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(loss_history)\n",
    "\n",
    "# save model\n",
    "time = time.strftime(\"%Y_%m_%d_%H_%M\", time.localtime())\n",
    "model_save_path = os.path.join(base_path, f\"gnn_parameters_{time}.pth\")\n",
    "\n",
    "# 假设在某个时间点需要保存模型，例如在训练结束或每隔一定轮数保存一次\n",
    "checkpoint = {\n",
    "    'epoch': current_epoch,\n",
    "    'model_state_dict': gcn_transformer.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(),\n",
    "    'hyperparameters': hyperparameters,\n",
    "    'loss_history': loss_history\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_optimizer = Adam(gcn_transformer.parameters(), lr=lr)\n",
    "# new_history = train_model(gcn_transformer, num_epochs, data_loader, new_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_history = loss_history + new_history\n",
    "# plot_losses(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time.strftime(\"%Y_%m_%d_%H_%M\", time.localtime())\n",
    "model_save_path = os.path.join(base_path, f\"gnn_parameters_{timestamp}.pth\")\n",
    "torch.save(gcn_transformer.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset size:\", len(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_idx  = 49\n",
    "test_graph_data = datasets[data_idx]\n",
    "test_ray_data = ray_datasets[data_idx]\n",
    "with torch.no_grad():\n",
    "    weights, mus, kappas = gcn_transformer.vmf_param(test_graph_data.x, test_graph_data.edge_index, test_graph_data.pos, test_graph_data.batch)\n",
    "    img_predict = multi_vmf(weights.squeeze(), mus.squeeze(), kappas.squeeze(), X).cpu().numpy() \n",
    "    img_predict = img_predict.reshape(sizes)\n",
    "\n",
    "    tgt_w, tgt_m, tgt_k = extract_param(test_graph_data.y)\n",
    "    img_reference = multi_vmf(tgt_w,tgt_m,tgt_k, X).cpu().numpy()\n",
    "    img_reference = img_reference.reshape(sizes)\n",
    "\n",
    "    # img_reference = test_ray_data.cpu().numpy().reshape(sizes[0], sizes[1])\n",
    "    plot_outputs_3d(img_reference, img_predict, sizes, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class GCN(torch.nn.Module):\n",
    "#     def __init__(self, num_features, hidden_channels):\n",
    "#         super(GCN, self).__init__()\n",
    "#         torch.manual_seed(12345)\n",
    "#         self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "#         self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "#         self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         x_0 = x.clone().detach()\n",
    "\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x = F.dropout(x, p=0.3, training=self.training)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x = F.dropout(x, p=0.3, training=self.training)\n",
    "#         x = self.conv3(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x = F.dropout(x, p=0.3, training=self.training)\n",
    "        \n",
    "#         x = torch.cat([x_0, x], dim=-1)\n",
    "        \n",
    "#         return x\n",
    "    \n",
    "#     def reset_parameters(self):\n",
    "#         self.conv1.reset_parameters()\n",
    "#         self.conv2.reset_parameters()\n",
    "#         self.conv3.reset_parameters()\n",
    "#         self.lin.reset_parameters()\n",
    "\n",
    "# class GNN(torch.nn.Module):\n",
    "#     def __init__(self, num_features, hidden_channels):\n",
    "#         super(GNN, self).__init__()\n",
    "#         torch.manual_seed(12345)\n",
    "#         self.conv1 = GraphConv(num_features, hidden_channels)\n",
    "#         self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "#         self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "#         self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         x_0 = x.clone().detach()\n",
    "\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x = F.dropout(x, p=0.3, training=self.training)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x = F.dropout(x, p=0.3, training=self.training)\n",
    "#         x = self.conv3(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x = F.dropout(x, p=0.3, training=self.training)\n",
    "\n",
    "#         x = torch.cat([x_0, x], dim=-1)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "# class GAT(torch.nn.Module):\n",
    "#     def __init__(self, num_features, hidden_channels, heads=8):\n",
    "#         super(GAT, self).__init__()\n",
    "#         torch.manual_seed(12345)\n",
    "#         self.conv1 = GATConv(num_features, hidden_channels, heads=heads, dropout=0.6)\n",
    "#         self.conv2 = GATConv(hidden_channels * heads, hidden_channels, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         x_0 = x.clone().detach()\n",
    "\n",
    "#         x = F.dropout(x, p=0.6, training=self.training)\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = F.elu(x)\n",
    "#         x = F.dropout(x, p=0.6, training=self.training)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "\n",
    "#         x = torch.cat([x_0, x], dim=-1)\n",
    "        \n",
    "#         return x\n",
    "    \n",
    "#     def reset_parameters(self):\n",
    "#         self.conv1.reset_parameters()\n",
    "#         self.conv2.reset_parameters()\n",
    "\n",
    "# class GraphSAGE(torch.nn.Module):\n",
    "#     def __init__(self, num_features, hidden_channels):\n",
    "#         super(GraphSAGE, self).__init__()\n",
    "#         torch.manual_seed(12345)\n",
    "#         self.conv1 = SAGEConv(num_features, hidden_channels)\n",
    "#         self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "#         self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         x_0 = x.clone().detach()\n",
    "\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x = F.dropout(x, p=0.3, training=self.training)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x = F.dropout(x, p=0.3, training=self.training)\n",
    "#         x = self.conv3(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x = F.dropout(x, p=0.3, training=self.training)\n",
    "\n",
    "#         x = torch.cat([x_0, x], dim=-1)\n",
    "        \n",
    "#         return x\n",
    "    \n",
    "#     def reset_parameters(self):\n",
    "#         self.conv1.reset_parameters()\n",
    "#         self.conv2.reset_parameters()\n",
    "#         self.conv3.reset_parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pbgnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
